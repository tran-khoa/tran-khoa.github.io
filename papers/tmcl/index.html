<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <meta
            http-equiv="Content-Security-Policy"
            content="upgrade-insecure-requests"
    />

    <title>
        Contrastive Consolidation of Top‑Down Modulations Achieves Sparsely
        Supervised Continual Learning
    </title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-sRIl4kxILFvY47J16cr9ZwB07vP4J8+LH7qKQnuqkuIAvNWLzeN8tE5YBujZqJLB" crossorigin="anonymous">
    <link rel="preconnect" href="https://fonts.googleapis.com"/>
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
    <link
            href="https://fonts.googleapis.com/css2?family=IBM+Plex+Serif:ital,wght@0,300;0,400;0,500;0,600;0,700;1,400&display=swap"
            rel="stylesheet"
    />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.13.1/font/bootstrap-icons.min.css">

    <link rel="stylesheet" href="custom.css"/>
</head>
<body>
<header>
    <div class="container">
        <div class="row">
            <div class="col mx-auto">
                <h1 id="title" class="text-center fs-4">
                    Contrastive&nbsp;Consolidation
                    <wbr/>
                    <span class="minor">of</span
                    >&nbsp;Top&#8209;Down&nbsp;Modulations
                    <wbr/>
                    <span class="minor">Achieves</span>&nbsp;Sparsely&nbsp;Supervised
                    Continual&nbsp;Learning
                </h1>
                <p class="author text-center lh-lg">
                    <a class="btn btn-light" href="https://ktran.de"
                    >Viet Anh Khoa Tran</a
                    >
                    <span class="mx-2">•</span>&nbsp;<a
                        class="btn btn-light"
                        href="https://scholar.google.com/citations?user=yYT6jtkAAAAJ"
                >Emre O. Neftci</a
                >
                    <span class="mx-2">•</span>&nbsp;<a
                        class="btn btn-light"
                        href="https://www.fz-juelich.de/en/pgi/pgi-15/research/dlg"
                >Willem A. M. Wybo</a
                >
                </p>

                <div class="affiliations d-flex justify-content-center">
                    <a href="https://www.fz-juelich.de/en/pgi/pgi-15/research/dlg">
                        <img
                                class="img-fluid"
                                src="dendlearn.svg"
                                alt="Forschungszentrum Jülich"
                        />
                    </a>
                </div>
            </div>
        </div>
    </div>
</header>

<main class="container row-gap-5">
    <div class="row actions">
        <div class="d-flex justify-content-center">
            <a href="https://arxiv.org/abs/2505.14125" type="button" class="btn btn-light btn-lg"><i
                    class="bi bi-journal-text"></i> Paper</a>
            <span class="mx-1"></span>
            <a href="https://github.com/tran-khoa/tmcl" type="button" class="btn btn-light btn-lg"><i
                    class="bi bi-code"></i> Code</a>
            <span class="mx-1"></span>
            <button type="button" class="btn btn-light btn-lg"  data-bs-custom-class="bibtex-popover user-select-all" data-bs-toggle="popover"
                    data-bs-placement="bottom" data-bs-content="@inproceedings{tran2025contrastive,
    title={Contrastive Consolidation of Top-Down Modulations Achieves Sparsely Supervised Continual Learning},
    author={Viet Anh Khoa Tran and Emre Neftci and Willem A.M. Wybo},
    booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},
    year={2025},
    url={https://openreview.net/forum?id=pLDpenGIjl}
}"><i
                    class="bi bi-quote"></i>
                BibTeX
            </button>
        </div>
    </div>

    <section id="figure1" class="row">
        <h5 class="display-6">
            A cortical representation learning algorithm...
        </h5>

        <figure>
            <img
                    src="newrips_fig1_web.svg"
                    alt="Task-Modulated Contrastive Learning"
                    class="mx-auto d-block mb-3"
                    width="80%"
            />
            <figcaption class="col-lg-10 mx-auto container d-grid row-gap-3">
                <div class="row justify-content-between row-gap-3">
                    <div class="col-md-6">
                        <strong>Left:</strong> Cortical learning is characterized by the
                        interplay between top-down (orange) and feedforward (blue)
                        processing, where top-down connections impart high-level
                        information on the feedforward sensory processing pathway (top).
                        The feedforward pathway, on the other hand, learns to predict
                        neural representations of future inputs (predictive coding).
                    </div>
                    <div class="col-md-6">
                        <strong>Right:</strong> In contrast, the traditional machine
                        learning approach of unsupervised pretraining for view
                        invariance (top) followed by supervised fine-tuning (bottom). In
                        this case, it is unclear how high-level information can be
                        incorporated into the sensory processing pathway to improve
                        subsequent learning.
                    </div>
                </div>
                <div class="row justify-content-center">
                    <div class="col-md-7">
                        <strong>Middle:</strong> Translating this view to a machine
                        learning algorithm, we (i) train modulations to implement
                        high-level object identification tasks as the analogue of
                        top-down inputs, while we (ii) train for view invariance over
                        modulated representations and for modulation invariance as the
                        analogue of predictive coding (top). As a consequence,
                        high-level information continually permeates into the sensory
                        processing pathway.
                    </div>
                </div>
            </figcaption>
        </figure>

        <h5 class="display-6">
            ... for sparsely supervised class-incremental representation learning
        </h5>
        <figure>
            <img
                    src="newrips_fig2_web.svg"
                    alt="Task-Modulated Contrastive Learning"
                    class="mx-auto d-block"
                    width="80%"
            />
        </figure>
    </section>
    <section id="abstract" class="row">
        <h5 class="display-5">Abstract</h5>
        <blockquote class="blockquote tldr">
            <p>
                Using contrastive learning to integrate class modulations into
                feedforward weights, continually.
            </p>
        </blockquote>
        <p>
            Biological brains learn continually from a stream of unlabeled data,
            while integrating specialized information from sparsely labeled
            examples without compromising their ability to generalize. Meanwhile,
            machine learning methods are susceptible to catastrophic forgetting in
            this natural learning setting, as supervised specialist fine-tuning
            degrades performance on the original task.
        </p>
        <p>
            We introduce
            <mark>task-modulated contrastive learning (TMCL)</mark>
            , which takes inspiration from the biophysical machinery in the
            neocortex, using predictive coding principles to integrate top-down
            information continually and without supervision. We follow the idea
            that these principles build a view-invariant representation space, and
            that this can be implemented using a contrastive loss. Then, whenever
            labeled samples of a new class occur, new affine modulations are
            learned that improve separation of the new class from all others,
            without affecting feedforward weights. By co-opting the
            view-invariance learning mechanism, we then train feedforward weights
            to match the unmodulated representation of a data sample to its
            modulated counterparts. This introduces modulation invariance into the
            representation space, and, by also using past modulations, stabilizes
            it.
        </p>
        <p>
            Our experiments show improvements in both class-incremental and
            transfer learning over state-of-the-art unsupervised approaches, as
            well as over comparable supervised approaches, using as few as 1% of
            available labels. Taken together, our work suggests that top-down
            modulations play a crucial role in balancing stability and plasticity.
        </p>
    </section>
    <section id="contact" class="row mt-4">
        <h5 class="display-7">Correspondence</h5>
        <code>{v.tran, w.wybo} [at] fz-juelich [dot] de</code>
    </section>
</main>
</body>

<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-FKyoEForCGlyvwx9Hj09JcYn3nv7wiPVlz7YYwJrWVcXK/BmnVDxM+D2scQbITxI"
        crossorigin="anonymous"></script>

<script>
    const popoverTriggerList = document.querySelectorAll('[data-bs-toggle="popover"]')
    const popoverList = [...popoverTriggerList].map(popoverTriggerEl => new bootstrap.Popover(popoverTriggerEl))

    const myDefaultAllowList = bootstrap.Tooltip.Default.allowList
    myDefaultAllowList.div = ['data-bs-content']
</script>
</html>
